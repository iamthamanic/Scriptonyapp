# âœ… AI CHAT TIMEOUT FIX - 2-PHASEN-ARCHITEKTUR

## ğŸ¯ Problem

**Symptom:** Request timed out after 30000ms
**Ursache:** GroÃŸe Tool-Operationen (z.B. 20 Szenen + 3 Charaktere erstellen) dauern zu lange:
1. AI identifiziert Tool Calls (~2s)
2. **Tools ausfÃ¼hren (20+ DB-Operationen) (~25s)**
3. Zweiter AI Call fÃ¼r finale Response (~5s)
4. **= 32 Sekunden â†’ TIMEOUT**

---

## âœ… LÃ¶sung: Asynchrone Tool Execution mit Sofortigem Feedback

### **Architektur:**

```
USER: "Erstelle Projekt Better Nine mit 20 Szenen"
  â†“
AI: Tool Calls identifiziert (CREATE_PROJECT, CREATE_SCENES[20])
  â†“
BACKEND: GeschÃ¤tzte Operationen = 21 (>10 Threshold)
  â†“
SOFORTIGE RESPONSE: "âœ… Verstanden! Ich erstelle jetzt: Projekt Better Nine, 20 Szenen"
  â†“ (User sieht sofort Feedback)
  â†“
BACKGROUND: Tools werden asynchron ausgefÃ¼hrt
  â†“
FOLLOW-UP MESSAGE: "ğŸ‰ Fertig! âœ… CREATE_PROJECT: Erfolgreich..."
  â†“
FRONTEND POLLING: LÃ¤dt neue Message alle 2s
  â†“
USER: Sieht Ergebnis automatisch
```

---

## ğŸ”§ Implementierung

### **1. Backend: ai-provider-calls.tsx**

```typescript
// Operationen schÃ¤tzen
const estimatedOps = message.tool_calls.reduce((sum, tc) => {
  const args = JSON.parse(tc.function.arguments);
  if (tc.function.name === 'CREATE_SCENES' && args.scenes) {
    return sum + args.scenes.length; // Jede Szene = 1 Operation
  }
  return sum + 1;
}, 0);

// Threshold: >10 Operationen = Immediate Response
if (estimatedOps > 10) {
  // Sofortige BestÃ¤tigung senden
  const immediateContent = "âœ… Verstanden! Ich erstelle jetzt: ...";
  
  // Tools im Hintergrund ausfÃ¼hren (Promise - kein await!)
  processToolCalls(data, config.toolsConfig, config.messages)
    .then(async (toolResult) => {
      // Follow-up Message in DB speichern
      await supabase.from("chat_messages").insert({
        content: "ğŸ‰ Fertig! ...",
        tool_calls: toolResult.toolCalls,
      });
    });
  
  // Sofort zurÃ¼ckgeben
  return { content: immediateContent, immediateResponse: true };
}
```

### **2. Frontend: ScriptonyAssistant.tsx**

```typescript
// Nach AI Response prÃ¼fen ob Background Tools laufen
const isBackgroundToolResponse = aiMsg.content.includes('â³ Dies kann einige Sekunden dauern');

if (isBackgroundToolResponse) {
  // Polling starten: Alle 2s neue Messages abfragen
  const pollInterval = setInterval(async () => {
    const pollResult = await apiGet(`/ai/conversations/${conversation_id}/messages`);
    const newerMessages = pollResult.data.messages.filter(
      msg => new Date(msg.created_at) > aiMsg.timestamp
    );
    
    if (newerMessages.length > 0) {
      setMessages(prev => [...prev, ...newerMessages]);
      clearInterval(pollInterval);
      toast.success('Aktionen abgeschlossen!');
    }
  }, 2000);
}
```

---

## ğŸŒ Multi-Provider Support

### **UnterstÃ¼tzte Provider:**

| Provider | Tool Support | Async Execution |
|----------|-------------|-----------------|
| âœ… **OpenAI** | âœ… Function Calling | âœ… Ja |
| âœ… **Anthropic** | âœ… Tool Use | âœ… Ja |
| âš ï¸ **Google Gemini** | âŒ Noch nicht | - |
| âœ… **OpenRouter** | âœ… Via OpenAI Format | âœ… Ja |

---

## ğŸ“Š Performance

### **Vorher:**
```
User Message â†’ 32 Sekunden â†’ TIMEOUT âŒ
```

### **Nachher:**
```
User Message â†’ 2 Sekunden â†’ Sofort-BestÃ¤tigung âœ…
Background: 25 Sekunden â†’ Follow-up Message âœ…
Total UX: 2 Sekunden fÃ¼r Feedback
```

---

## ğŸ¯ User Experience

### **Beispiel-Flow:**

1. **User schreibt:**
   ```
   Erstelle ein Film-Projekt "Better Nine" mit 20 Szenen und 3 Charakteren
   ```

2. **Sofortige Antwort (2s):**
   ```
   âœ… Verstanden! Ich erstelle jetzt: Projekt "Better Nine", 20 Szenen, 3 Charaktere
   
   â³ Dies kann einige Sekunden dauern...
   ```

3. **Automatische Follow-Up Message (nach ~25s):**
   ```
   ğŸ‰ Fertig!
   
   âœ… CREATE_PROJECT: Projekt "Better Nine" erfolgreich erstellt
   âœ… CREATE_SCENES: 20 Szenen erstellt
   âœ… CREATE_CHARACTERS: 3 Charaktere erstellt
   ```

---

## ğŸ”’ Fehlerbehandlung

### **Wenn Background-Tools fehlschlagen:**

```typescript
// In ai-provider-calls.tsx
processToolCalls(...).catch(err => {
  console.error('âŒ Background tool execution failed:', err);
  
  // Fehler-Message in DB speichern
  await supabase.from("chat_messages").insert({
    content: `âŒ Fehler beim AusfÃ¼hren der Aktionen:\n\n${err.message}`,
    role: "assistant",
  });
});
```

### **Polling Timeout:**

- Maximal **30 Polls** (= 60 Sekunden)
- Danach automatisch stoppen
- User kann Chat weiter nutzen

---

## ğŸš€ Threshold-Konfiguration

**Aktueller Threshold:** 10 Operationen

### **Beispiele:**

| Aktion | Operationen | Async? |
|--------|------------|--------|
| CREATE_PROJECT | 1 | âŒ Normal |
| CREATE_SCENES (5 Szenen) | 5 | âŒ Normal |
| CREATE_SCENES (20 Szenen) | 20 | âœ… Async |
| CREATE_PROJECT + CREATE_SCENES (20) | 21 | âœ… Async |
| UPDATE_SCENES (50 Updates) | 50 | âœ… Async |

### **Anpassen:**

```typescript
// In ai-provider-calls.tsx, Zeile ~80
if (estimatedOps > 10) { // â† Hier Threshold Ã¤ndern
```

---

## ğŸ“ Console Logs

### **Erfolgreich:**

```
ğŸ”§ OpenAI requested 3 tool calls
ğŸ“Š Estimated operations: 21
âš¡ High operation count detected - returning immediate response
âœ… Background tools completed: 3 calls
âœ… Follow-up message saved
â³ Background tools detected - polling for follow-up message...
âœ… Found 1 new message(s) - updating chat
```

### **Bei Fehler:**

```
ğŸ”§ OpenAI requested 3 tool calls
ğŸ“Š Estimated operations: 21
âš¡ High operation count detected - returning immediate response
âŒ Background tool execution failed: Database error
```

---

## ğŸ¯ Vorteile

âœ… **Keine Timeouts** - Sofortige Response verhindert 30s-Limit
âœ… **Multi-Provider** - Funktioniert mit OpenAI, Anthropic, OpenRouter
âœ… **Bessere UX** - User sieht sofort Feedback
âœ… **Skalierbar** - Egal wie viele Operationen
âœ… **Fehler-Tolerant** - Background-Fehler crashen nicht die UI
âœ… **Real-Time Updates** - Polling zeigt Ergebnisse automatisch

---

## ğŸ”„ Migration

### **Keine Breaking Changes:**

- Alte Tool Calls (â‰¤10 Ops) funktionieren wie vorher
- Nur groÃŸe Operationen nutzen neue Async-Logik
- Automatische Detection via Threshold

---

## ğŸ§ª Testen

### **Test-Prompt:**

```
Erstelle ein Film-Projekt "Better Nine" mit 20 Szenen und 3 Charakteren
```

### **Erwartete Console Logs:**

```
[1] ğŸ”§ OpenAI requested 3 tool calls
[2] ğŸ“Š Estimated operations: 21
[3] âš¡ High operation count detected - returning immediate response
[4] â³ Background tools detected - polling for follow-up message...
[5] âœ… Background tools completed: 3 calls
[6] âœ… Follow-up message saved: abc-123-def
[7] âœ… Found 1 new message(s) - updating chat
[8] âœ… Aktionen abgeschlossen!
```

### **Erwartete UI:**

1. **Sofort:** BestÃ¤tigungsnachricht mit â³
2. **Nach ~25s:** Follow-up Message mit âœ…/âŒ Status
3. **Toast:** "Aktionen abgeschlossen!"

---

## ğŸ“š Verwandte Dateien

- `/supabase/functions/server/ai-provider-calls.tsx` - Async Tool Execution
- `/supabase/functions/server/routes-ai-chat.tsx` - Chat Route
- `/components/ScriptonyAssistant.tsx` - Frontend Polling
- `/supabase/functions/server/tools-integration.tsx` - Tool Processing

---

**Status:** âœ… IMPLEMENTIERT & GETESTET
**Datum:** 2025-01-15
**Version:** 2.0 (2-Phasen-Architektur)
